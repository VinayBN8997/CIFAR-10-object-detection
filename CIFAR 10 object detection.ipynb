{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7633,
     "status": "ok",
     "timestamp": 1540619514847,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "K70hAckqg0EA",
    "outputId": "b24fc4d7-4662-450a-8151-c246d7e61d11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LmhFRhn3w5rO"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vp37AkT31wtS"
   },
   "source": [
    "# CNN Architecture: Densely Connected Convolutional Networks\n",
    "\n",
    "Source: https://arxiv.org/abs/1608.06993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXdoRa5a149E"
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*_Y7-f9GpV7F93siM1js0cg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KUQV9mO18lh"
   },
   "source": [
    "# Major insights from the paper:\n",
    "\n",
    "    1. To further improve the information flow between layers inside a dense block, a different connectivity pattern is introduced which are direct connections from any layer to all subsequent layers.\n",
    "    2. Each dense block has a composite function of three consecutive operations as batch normalization (BN), followed by a rectified linear unit (ReLU) and a 3 × 3 convolution (Conv).\n",
    "    3. The transition layers used in our experiments consist of a batch normalization layer and an 1×1 convolutional layer followed by a 2×2 average pooling layer.\n",
    "    4. An important difference between DenseNet and existing network architectures is that DenseNet can have very narrow layers, e.g., k = 12. Here k is the growth rate which represents the number of feature maps for each layer of convolution.\n",
    "    5. A 1×1 convolution is be introduced as bottleneck layer before each 3×3 convolution to reduce the number of input feature-maps, and thus to improve computational efficiency.\n",
    "    6. To further improve model compactness, the number of feature-maps at transition layers is reduced uisng a compression factor. If a dense block contains m feature-maps, the following transition layer generate θ*m output featuremaps.\n",
    "    7. At the end of the last dense block, i.e, in the output block, a global average pooling is performed and then a softmax classifier is attached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fdOetN8w9IB"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "l = 40\n",
    "num_filter = 24\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhY8q6li1lZJ"
   },
   "source": [
    "# About Data:\n",
    "\n",
    "The **CIFAR-10 **dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains **60,000 32x32 color images in 10 different classes**. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. CIFAR-10 is a labeled subset of the 80 million tiny images dataset.\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYvOwqhr1m8X"
   },
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/356/1*QN007xhxgDTPBdNT0pnZ2g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AK4eudbgw_os"
   },
   "source": [
    "# Importing data and converting output variable to one-hot vector form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107211,
     "status": "ok",
     "timestamp": 1540619628113,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "mB7o3zu1g6eT",
    "outputId": "2efaeadf-2163-4251-e0ce-d098fe5c3633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 103s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gm81G__PxJc0"
   },
   "source": [
    "# Normalising Data\n",
    "\n",
    "It is required to normalize the data so that all features come to a scale between 0 and 1. This helps better understanding by the network. It is also required to convert the data type of individual pixel value to float before normalization because float is more accurate than integers.\n",
    "\n",
    "**Caution:** If data type in not converted to float before dividing, then we may end up ceiling the data if proper typecast is not done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Io9V5hFjGJfp"
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EOKqQmYNxL5I"
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Data Augmentation is a great method to **indirectly acquire more data** from the already availabe data. This happens by horizontal or verticle flips, rotation of images, random cropping and many more image processing ways such as whitening, scaling and different channels improvization. \n",
    "Helps in generalization process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdaM7goRIkra"
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QsudiUKxRa_"
   },
   "source": [
    "# Dense Block\n",
    "\n",
    "This is the actual feature extracter block.\n",
    "\n",
    "   1.  Architecture has **3 dense blocks**.\n",
    "    Batch Normalization helps in **equalising the outcome values** from convolution.\n",
    "    2. Activation function: **RELU**\n",
    "    3. **Dropout** is done after 3x3 convolution for **regularization purpose** where 20% of neurons are randomly shut down to avoid overfitting on train data.\n",
    "    4. **1x1 Convolution** is done to to reduce the number of channels before giving it to next layer so that it helps in achieving lower number of parameters and reducing model complexity.\n",
    "    5. Standard **3x3 Convolution** is followed.\n",
    "    6. The number of filters used in 1x1 is **four times(4x) the number of kernals** in 3x3 convolution as advised by the above mentioned paper. This helps by not losing too much of information when reduing the number of channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34VDEiAd8DV5"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = 16, dropout_rate = 0.25):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "      \n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        reluD_LAYER = Activation('relu')(BatchNorm)\n",
    "        Conv2D_1_1 = Conv2D(int(4*num_filter*compression), (1,1), use_bias=False ,padding='same')(reluD_LAYER)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
    "          \n",
    "        BatchNorm = BatchNormalization()(Conv2D_1_1)\n",
    "        reluD_LAYER = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(reluD_LAYER)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAR4wxcFxT66"
   },
   "source": [
    "# Transition Block\n",
    "\n",
    "This is a transition block between 2 dense block.\n",
    "\n",
    "    1. 1x1 convolution is done for reducing the number of parameters. This is called as **BottleNeck layer** in the reference paper.\n",
    "    2. **Average pooling** is is done to reduce the feature map size from N to N/2 as pooling size is 2x2. i.e, stride of 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = 16, dropout_rate = 0.25):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(4*num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_DQ12IyxXHp"
   },
   "source": [
    "# Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gpXXU4k3IIu"
   },
   "source": [
    "This is the final layer of the model.\n",
    "\n",
    "    1. **Global Average pooling** is done here as advised from the reference paper. It does the **spatial average of the feature maps** of the previous layer. Another advantage here is that there is no parameter to optimize on its own by working on the spacial information.\n",
    "\n",
    "    2. **A dense layer** is added in the end to with **Softmax activation **and result is brouht to a vector of 10 values as required. Here softmax gives results which are **probability-like values**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    GblAvgPooling = GlobalAveragePooling2D()(relu)\n",
    "    #flat = Flatten()(GblAvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(GblAvgPooling)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5olrMedxZrt"
   },
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "\n",
    "l = 16\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "l = 16\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "l = 16\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "#l = 16\n",
    "#Forth_Block = add_denseblock(Third_Transition, num_filter, dropout_rate)\n",
    "#Forth_Transition = add_transition(Forth_Block, num_filter, dropout_rate)\n",
    "\n",
    "#Fifth_Block = add_denseblock(Forth_Transition, num_filter, dropout_rate)\n",
    "#Fifth_Transition = add_transition(Fifth_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 21542
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1561,
     "status": "ok",
     "timestamp": 1540619659327,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "1kFh7pdxhNtT",
    "outputId": "64a75bef-5832-4f53-bb46-cb7c41ce5279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 48)   5760        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 48)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 48)   192         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 12)   5184        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 12)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 132)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 48)   6336        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 48)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 48)   192         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 12)   5184        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 12)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 144)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 48)   6912        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 12)   5184        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 12)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 156)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 48)   7488        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 32, 48)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 12)   5184        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 32, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 168)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 168)  672         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 168)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 48)   8064        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 32, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 48)   192         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 48)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 12)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 32, 12)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 180)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 180)  720         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 180)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 48)   8640        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 32, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 48)   192         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 12)   5184        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 32, 12)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 192)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 192)  768         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 192)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 48)   9216        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 32, 48)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 48)   192         dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 48)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 12)   5184        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 32, 12)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32, 32, 204)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 204)  816         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 204)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 48)   9792        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 32, 32, 48)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 48)   192         dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 48)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 12)   5184        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32, 32, 12)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 216)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 216)  864         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 216)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 48)   10368       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 32, 32, 48)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 48)   0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 48)   192         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 48)   2304        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 12)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 60)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 60)   240         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 60)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   2880        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 12)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 72)   0           concatenate_17[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 72)   288         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 72)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 48)   3456        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 12)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 84)   0           concatenate_18[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 84)   336         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 84)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 48)   4032        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 12)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 96)   0           concatenate_19[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 96)   384         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 96)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   4608        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 12)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 108)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 108)  432         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 108)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 48)   5184        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 48)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 12)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 120)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 120)  480         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 120)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 48)   5760        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 48)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 12)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 132)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 132)  528         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 132)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   6336        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 48)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 144)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 144)  576         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 144)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 48)   6912        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 48)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 48)   192         dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 12)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 156)  0           concatenate_24[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 156)  624         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 156)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 48)   7488        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 48)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 48)   192         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 16, 16, 12)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 168)  0           concatenate_25[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 168)  672         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 168)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 48)   8064        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 16, 16, 48)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 48)   192         dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 16, 16, 12)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 180)  0           concatenate_26[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 180)  720         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 180)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 48)   8640        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 16, 16, 48)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 48)   192         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 16, 16, 12)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 192)  0           concatenate_27[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 192)  768         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 48)   9216        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 16, 16, 48)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 48)   192         dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 12)   5184        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 16, 16, 12)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 16, 16, 204)  0           concatenate_28[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 204)  816         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 204)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 48)   9792        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 16, 16, 48)   0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 48)   192         dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 48)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 12)   5184        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 16, 16, 12)   0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 16, 16, 216)  0           concatenate_29[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 216)  864         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 216)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 48)   10368       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 16, 16, 48)   0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 48)   192         dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 48)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 12)   5184        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 16, 16, 12)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 228)  0           concatenate_30[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 228)  912         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 228)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 48)   10944       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 16, 16, 48)   0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 48)   192         dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 12)   5184        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 16, 16, 12)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 16, 16, 240)  0           concatenate_31[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 240)  960         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 240)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 48)   11520       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 16, 16, 48)   0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 48)     0           dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 48)     192         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 48)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 48)     2304        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 60)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 60)     240         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 60)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 48)     2880        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 72)     0           concatenate_33[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 72)     288         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 72)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 48)     3456        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 84)     0           concatenate_34[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 84)     336         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 84)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 48)     4032        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 96)     0           concatenate_35[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 96)     384         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 96)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 48)     4608        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 108)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 108)    432         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 108)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 48)     5184        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 120)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 120)    480         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 120)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 48)     5760        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 132)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 132)    528         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 132)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 48)     6336        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 144)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 144)    576         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 144)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 48)     6912        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 156)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 156)    624         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 156)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 48)     7488        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 168)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 168)    672         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 168)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 48)     8064        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 48)     0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 180)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 180)    720         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 180)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 48)     8640        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 48)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 192)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 192)    768         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 192)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 48)     9216        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 48)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 48)     192         dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 48)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 12)     5184        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 12)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 8, 8, 204)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 204)    816         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 204)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 48)     9792        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 48)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 48)     192         dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 48)     0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 12)     5184        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 12)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 8, 8, 216)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 216)    864         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 216)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 48)     10368       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 48)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 48)     192         dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 48)     0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 12)     5184        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 12)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 8, 8, 228)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 228)    912         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 228)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 48)     10944       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 8, 8, 48)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 48)     192         dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 48)     0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 12)     5184        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 8, 8, 12)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 240)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 240)    960         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 240)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 48)     11520       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 8, 8, 48)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 48)     0           dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 48)     192         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 48)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 48)     2304        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 48)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 48)     192         dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 48)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 12)     5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 12)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 60)     0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 60)     240         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 60)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 48)     2880        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 48)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 48)     192         dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 48)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 12)     5184        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 12)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 72)     0           concatenate_49[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 72)     288         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 72)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 48)     3456        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 48)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 48)     192         dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 48)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 12)     5184        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 4, 4, 12)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 4, 4, 84)     0           concatenate_50[0][0]             \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 84)     336         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 84)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 48)     4032        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 48)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 48)     192         dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 48)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 12)     5184        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 12)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 4, 4, 96)     0           concatenate_51[0][0]             \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 96)     384         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 96)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 48)     4608        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 48)     0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 48)     192         dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 48)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 12)     5184        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 12)     0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 4, 4, 108)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 108)    432         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 108)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 48)     5184        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 48)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 48)     192         dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 48)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 12)     5184        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 12)     0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 4, 4, 120)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 120)    480         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 120)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 48)     5760        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 48)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 48)     192         dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 48)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 12)     5184        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 12)     0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 4, 4, 132)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 132)    528         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 132)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 48)     6336        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 48)     0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 48)     192         dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 48)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 12)     5184        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 12)     0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 144)    0           concatenate_55[0][0]             \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 144)    576         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 144)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 4, 4, 48)     6912        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 4, 4, 48)     0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 4, 4, 48)     192         dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 4, 4, 48)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 4, 4, 12)     5184        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 4, 4, 12)     0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 4, 4, 156)    0           concatenate_56[0][0]             \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 4, 4, 156)    624         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 4, 4, 156)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 4, 4, 48)     7488        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 4, 4, 48)     0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 4, 4, 48)     192         dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 4, 4, 48)     0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 4, 4, 12)     5184        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 4, 4, 12)     0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 4, 4, 168)    0           concatenate_57[0][0]             \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 4, 4, 168)    672         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 168)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 4, 4, 48)     8064        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 4, 4, 48)     0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 4, 4, 48)     192         dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 4, 4, 48)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 4, 4, 12)     5184        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 4, 4, 12)     0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 4, 4, 180)    0           concatenate_58[0][0]             \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 4, 4, 180)    720         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 4, 4, 180)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 4, 4, 48)     8640        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 4, 4, 48)     0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 4, 4, 48)     192         dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 48)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 4, 4, 12)     5184        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 4, 4, 12)     0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 4, 4, 192)    0           concatenate_59[0][0]             \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 4, 4, 192)    768         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 4, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 4, 4, 48)     9216        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 4, 4, 48)     0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 4, 48)     192         dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 4, 48)     0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 4, 4, 12)     5184        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 4, 4, 12)     0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 4, 4, 204)    0           concatenate_60[0][0]             \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 204)    816         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 4, 204)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 4, 4, 48)     9792        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 4, 4, 48)     0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 48)     192         dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 4, 48)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 4, 4, 12)     5184        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 4, 4, 12)     0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 4, 4, 216)    0           concatenate_61[0][0]             \n",
      "                                                                 dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 216)    864         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 4, 216)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 4, 4, 48)     10368       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 4, 4, 48)     0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 48)     192         dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 4, 48)     0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, 4, 12)     5184        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 4, 4, 12)     0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 4, 4, 228)    0           concatenate_62[0][0]             \n",
      "                                                                 dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 228)    912         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 4, 228)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, 4, 48)     10944       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 4, 4, 48)     0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 48)     192         dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 48)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, 4, 12)     5184        activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 4, 4, 12)     0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 4, 4, 240)    0           concatenate_63[0][0]             \n",
      "                                                                 dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 240)    960         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 240)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 240)          0           activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2410        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 823,570\n",
      "Trainable params: 798,658\n",
      "Non-trainable params: 24,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_OUhYeE-ANZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8723,
     "status": "ok",
     "timestamp": 1540619669590,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "cbY9yw63IObn",
    "outputId": "c186bc5f-fd1a-44df-c247-48797af041e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-10-27 05:54:25--  https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
      "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py [following]\n",
      "--2018-10-27 05:54:25--  https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5326 (5.2K) [text/plain]\n",
      "Saving to: ‘clr_callback.py’\n",
      "\n",
      "clr_callback.py     100%[===================>]   5.20K  --.-KB/s    in 0s      \n",
      "\n",
      "2018-10-27 05:54:26 (59.1 MB/s) - ‘clr_callback.py’ saved [5326/5326]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -rf clr_callback.py*\n",
    "!wget https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
    "from clr_callback import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-i1N5Spxera"
   },
   "source": [
    "# Different learning rate decay algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9qwBkMu3eVE"
   },
   "source": [
    "## 1. Learning Rate Schedular from keras\n",
    "This reduces the value according to the formula given below. This reduces the learning rate value gradually at each epoch.\n",
    "\n",
    "# LR = initial_LR * drop**( (1 + epoch) / epochs_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep-T_WB7yRo_"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.1\n",
    "\tdrop = 0.7\n",
    "\tepochs_drop = 20.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XILHmv-5ypdQ"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_FkgDRi3lyX"
   },
   "source": [
    "## 2. Reduce LR on Plateau\n",
    "\n",
    "This changes the learning rate when the model is not learning anymore based on validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDgFLX-PWjd2"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6gmkSVu-eQG"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqcFtwgLxjuf"
   },
   "outputs": [],
   "source": [
    "# Saving the best model based on validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aLo00ClqFHZC"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=\"Assignment_4.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3wPXHXJUDKl"
   },
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4467
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30803973,
     "status": "error",
     "timestamp": 1540650723531,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "CbsRsuC6iS6F",
    "outputId": "7ff8c588-2b53-457c-e2f8-b6e65c3afcd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "703/703 [==============================] - 706s 1s/step - loss: 1.3346 - acc: 0.5142 - val_loss: 1.8051 - val_acc: 0.5197\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51970, saving model to Assignment_4.hdf5\n",
      "Epoch 2/50\n",
      "703/703 [==============================] - 674s 959ms/step - loss: 0.9984 - acc: 0.6440 - val_loss: 1.2943 - val_acc: 0.5974\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.51970 to 0.59740, saving model to Assignment_4.hdf5\n",
      "Epoch 3/50\n",
      "703/703 [==============================] - 674s 959ms/step - loss: 0.8626 - acc: 0.6942 - val_loss: 1.3051 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.59740 to 0.64460, saving model to Assignment_4.hdf5\n",
      "Epoch 4/50\n",
      "703/703 [==============================] - 675s 960ms/step - loss: 0.7641 - acc: 0.7332 - val_loss: 1.0603 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.64460 to 0.68840, saving model to Assignment_4.hdf5\n",
      "Epoch 5/50\n",
      "703/703 [==============================] - 680s 967ms/step - loss: 0.6897 - acc: 0.7585 - val_loss: 1.1010 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.68840 to 0.69460, saving model to Assignment_4.hdf5\n",
      "Epoch 6/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.6320 - acc: 0.7782 - val_loss: 0.9678 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.69460 to 0.72940, saving model to Assignment_4.hdf5\n",
      "Epoch 7/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.5791 - acc: 0.7976 - val_loss: 0.9954 - val_acc: 0.7316\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72940 to 0.73160, saving model to Assignment_4.hdf5\n",
      "Epoch 8/50\n",
      "703/703 [==============================] - 676s 962ms/step - loss: 0.5490 - acc: 0.8087 - val_loss: 0.6693 - val_acc: 0.7967\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.73160 to 0.79670, saving model to Assignment_4.hdf5\n",
      "Epoch 9/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.5134 - acc: 0.8214 - val_loss: 0.5741 - val_acc: 0.8282\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.79670 to 0.82820, saving model to Assignment_4.hdf5\n",
      "Epoch 10/50\n",
      "703/703 [==============================] - 678s 964ms/step - loss: 0.4878 - acc: 0.8300 - val_loss: 0.5668 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.82820\n",
      "Epoch 11/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.4685 - acc: 0.8370 - val_loss: 0.5329 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.82820 to 0.84170, saving model to Assignment_4.hdf5\n",
      "Epoch 12/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.4476 - acc: 0.8451 - val_loss: 0.5151 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.84170 to 0.85030, saving model to Assignment_4.hdf5\n",
      "Epoch 13/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.4279 - acc: 0.8514 - val_loss: 0.5275 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.85030\n",
      "Epoch 14/50\n",
      "703/703 [==============================] - 677s 962ms/step - loss: 0.4141 - acc: 0.8564 - val_loss: 0.6803 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.85030\n",
      "Epoch 15/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.3958 - acc: 0.8608 - val_loss: 0.6437 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.85030\n",
      "Epoch 16/50\n",
      "703/703 [==============================] - 677s 963ms/step - loss: 0.3384 - acc: 0.8822 - val_loss: 0.4144 - val_acc: 0.8772\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.85030 to 0.87720, saving model to Assignment_4.hdf5\n",
      "Epoch 17/50\n",
      "703/703 [==============================] - 678s 964ms/step - loss: 0.3200 - acc: 0.8882 - val_loss: 0.4058 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.87720 to 0.88020, saving model to Assignment_4.hdf5\n",
      "Epoch 18/50\n",
      "703/703 [==============================] - 676s 962ms/step - loss: 0.3091 - acc: 0.8917 - val_loss: 0.4066 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.88020 to 0.88190, saving model to Assignment_4.hdf5\n",
      "Epoch 19/50\n",
      "703/703 [==============================] - 677s 962ms/step - loss: 0.3033 - acc: 0.8940 - val_loss: 0.3892 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.88190 to 0.88380, saving model to Assignment_4.hdf5\n",
      "Epoch 20/50\n",
      "703/703 [==============================] - 677s 962ms/step - loss: 0.2982 - acc: 0.8951 - val_loss: 0.3988 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.88380 to 0.88480, saving model to Assignment_4.hdf5\n",
      "Epoch 21/50\n",
      "703/703 [==============================] - 676s 962ms/step - loss: 0.2926 - acc: 0.8972 - val_loss: 0.3672 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.88480 to 0.89360, saving model to Assignment_4.hdf5\n",
      "Epoch 22/50\n",
      "703/703 [==============================] - 680s 967ms/step - loss: 0.2854 - acc: 0.8999 - val_loss: 0.4041 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89360\n",
      "Epoch 23/50\n",
      "703/703 [==============================] - 680s 967ms/step - loss: 0.2837 - acc: 0.8994 - val_loss: 0.4284 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89360\n",
      "Epoch 24/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2840 - acc: 0.9001 - val_loss: 0.4186 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89360\n",
      "Epoch 25/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2682 - acc: 0.9061 - val_loss: 0.3820 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89360\n",
      "Epoch 26/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2628 - acc: 0.9064 - val_loss: 0.3864 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89360\n",
      "Epoch 27/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2583 - acc: 0.9080 - val_loss: 0.3715 - val_acc: 0.8925\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89360\n",
      "Epoch 28/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2615 - acc: 0.9074 - val_loss: 0.3832 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89360\n",
      "Epoch 29/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2578 - acc: 0.9093 - val_loss: 0.3760 - val_acc: 0.8947\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.89360 to 0.89470, saving model to Assignment_4.hdf5\n",
      "Epoch 30/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2599 - acc: 0.9079 - val_loss: 0.3830 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89470\n",
      "Epoch 31/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2584 - acc: 0.9086 - val_loss: 0.3751 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89470\n",
      "Epoch 32/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2552 - acc: 0.9100 - val_loss: 0.4077 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89470\n",
      "Epoch 33/50\n",
      "703/703 [==============================] - 681s 969ms/step - loss: 0.2552 - acc: 0.9096 - val_loss: 0.3917 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89470\n",
      "Epoch 34/50\n",
      "703/703 [==============================] - 681s 969ms/step - loss: 0.2520 - acc: 0.9114 - val_loss: 0.3948 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89470\n",
      "Epoch 35/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2536 - acc: 0.9110 - val_loss: 0.3849 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89470\n",
      "Epoch 36/50\n",
      "703/703 [==============================] - 681s 969ms/step - loss: 0.2535 - acc: 0.9098 - val_loss: 0.3918 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89470\n",
      "Epoch 37/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2498 - acc: 0.9120 - val_loss: 0.3812 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.89470 to 0.89490, saving model to Assignment_4.hdf5\n",
      "Epoch 38/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2465 - acc: 0.9134 - val_loss: 0.3723 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.89490 to 0.89630, saving model to Assignment_4.hdf5\n",
      "Epoch 39/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2486 - acc: 0.9116 - val_loss: 0.3828 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89630\n",
      "Epoch 40/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2465 - acc: 0.9134 - val_loss: 0.4097 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89630\n",
      "Epoch 41/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2471 - acc: 0.9132 - val_loss: 0.3808 - val_acc: 0.8956\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89630\n",
      "Epoch 42/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2446 - acc: 0.9133 - val_loss: 0.3915 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89630\n",
      "Epoch 43/50\n",
      "703/703 [==============================] - 680s 967ms/step - loss: 0.2410 - acc: 0.9144 - val_loss: 0.4062 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89630\n",
      "Epoch 44/50\n",
      "703/703 [==============================] - 680s 968ms/step - loss: 0.2445 - acc: 0.9145 - val_loss: 0.3870 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89630\n",
      "Epoch 45/50\n",
      "703/703 [==============================] - 681s 968ms/step - loss: 0.2431 - acc: 0.9135 - val_loss: 0.3908 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89630\n",
      "Epoch 46/50\n",
      " 19/703 [..............................] - ETA: 10:39 - loss: 0.2586 - acc: 0.9087"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4409a84ae8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),epochs=epochs,verbose=1,steps_per_epoch= 1.8*x_train.shape[0]//batch_size,callbacks=[reduce_lr,checkpoint],validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31529,
     "status": "ok",
     "timestamp": 1540652629703,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "xVa047XZDPsc",
    "outputId": "faf9b503-4413-48d7-a758-f8d3c61f5c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s 3ms/step\n",
      "Test loss: 0.3867398366123438\n",
      "Test accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVV5hX0P3pvJ"
   },
   "source": [
    "# Best Validation Accuracy: 89.45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1723,
     "status": "ok",
     "timestamp": 1540650783944,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "UE3lF6EH1r_L",
    "outputId": "424798f1-a4cb-4f00-f9ff-64d48218358c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_weigts_Best.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2692,
     "status": "ok",
     "timestamp": 1540650786876,
     "user": {
      "displayName": "VINAY BN",
      "photoUrl": "https://lh6.googleusercontent.com/-J_mdXgMj1nc/AAAAAAAAAAI/AAAAAAAAAvE/b4LB85JJRyc/s64/photo.jpg",
      "userId": "16228185655248237529"
     },
     "user_tz": -330
    },
    "id": "2CgNT2IPfuLv",
    "outputId": "e6a48c3e-7dd5-47f7-c00d-ea27e3a2a720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model in to .h5 format\n",
    "model.save(\"DNST_model_Best.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCor0g4ZwLHV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufkHvVMACAbC"
   },
   "source": [
    "# Remarks\n",
    "\n",
    "### I had the same model without the dropout after the 1x1 convolution in dense block which gave 91% accuracy. Unfortunately I modified it and no time left for deadline.\n",
    "\n",
    "### But I'm confident to tell that by removing the droppot after 1x1 in dense block and train for 50 epochs, this model will give better results.\n",
    "\n",
    "### Among Cyclic LR, LR Schedular and ReduceLRonPlateua, the last one gave best results.\n",
    "\n",
    "### CyclicLR gave the better initial learning among the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGGs18mU9f6P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EIP-2 Assignment 4 Vinay BN Batch 8.ipynb",
   "provenance": [
    {
     "file_id": "1O2sDOIqykDnq2--3UXJ32mEniAElwuw-",
     "timestamp": 1540619438703
    },
    {
     "file_id": "1NaCKKIa7KT47yMS24HEeNq08lb6PqAgA",
     "timestamp": 1540556904432
    },
    {
     "file_id": "1IEOtGIi7O_Vqx4aDMoz1cS7W5k8eILs6",
     "timestamp": 1540363613703
    },
    {
     "file_id": "1lOuSHY9GJvvJfd9R6CZyrh8dSufIdCwa",
     "timestamp": 1540125181046
    },
    {
     "file_id": "1d6kr6jZVioh6DDj5HK_LxLM_6mNLzpEA",
     "timestamp": 1540115815568
    },
    {
     "file_id": "1bCvVi3G_A2CocA9YZvQjIhUGLhHXpBmB",
     "timestamp": 1540089711430
    },
    {
     "file_id": "1ou7ljUTIuYncLwn-RsOVquFfy100jExs",
     "timestamp": 1539863542459
    },
    {
     "file_id": "1pFn0wvWOKj93A4_-pjMxsxR96VDyN-NF",
     "timestamp": 1539566959800
    },
    {
     "file_id": "1_1kwmwgL7g94jI6BEtcgm-D2_AFk0zxK",
     "timestamp": 1519101209834
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
